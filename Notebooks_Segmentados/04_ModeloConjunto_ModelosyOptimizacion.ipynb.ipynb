{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec91e29-59b9-4760-a40d-7cfc86634f94",
   "metadata": {},
   "source": [
    "# Modelo Conjunto GrandSlams + Masters1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4b1d4-978a-4bb9-927a-864fe876e042",
   "metadata": {},
   "source": [
    "## Modelo Regresi贸n Logistica (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f569ca-ad40-41cb-9776-b4b9bceb881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a escalar\n",
    "features_to_scale = [\n",
    "    \"Surface_WinRate_Favorite\", \"Surface_WinRate_Not_Favorite\",\n",
    "    \"Surface_Matches_Favorite\", \"Surface_Matches_Not_Favorite\",\n",
    "    \"WinStreak_Favorite\", \"WinStreak_Not_Favorite\", \"Win_Streak_Diff\",\n",
    "    \"Rank_Favorite\", \"Rank_Not_Favorite\", \"Rank_Diff_Signed\", \"Rank_Diff_Abs\",\n",
    "    \"GrandSlams_Favorite\", \"GrandSlams_Not_Favorite\",\n",
    "    \"Masters1000_Favorite\",\"Masters1000_Not_Favorite\"\n",
    "]\n",
    "\n",
    "# Asegurarse de que son num茅ricos\n",
    "for col in features_to_scale:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Escalado con StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d662e-e782-4db4-a73d-190fe8b1086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar los valores nulos por columna para comprobar que no haya nulos\n",
    "print(df[features_to_scale + [\"Favorite_Wins\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf2bea-8eea-4e4c-80bf-576921bd0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features_to_scale]  # Asegurarse de que no haya columnas extra\n",
    "y = df[\"Favorite_Wins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5d245-1859-49b0-bfc7-743e73acb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos que no haya nulos en x ni en y\n",
    "print(\"驴NaNs en X?:\", X.isna().any().any()) \n",
    "print(\"驴NaNs en y?:\", y.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bf61e-7bcc-477f-a987-ee8f986587cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo de regresi贸n log铆stica\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicci贸n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la m茅trica\n",
    "score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee53f3-2d1d-47d9-9d8b-94c235c56baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680cd01-25b5-4319-bc30-43c1f388cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo de regresi贸n log铆stica con ajuste por desbalance\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicci贸n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar con balanced accuracy\n",
    "score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac1d5b-7630-48b7-b69b-3782eeec0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba con validaci贸n cruzada\n",
    "\n",
    "# Usamos solo las columnas que queremos escalar\n",
    "X = df[features_to_scale]\n",
    "y = df[\"Favorite_Wins\"]  \n",
    "\n",
    "# Modelo con validaci贸n cruzada (5 folds)\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "# Evaluaci贸n\n",
    "score_cv = balanced_accuracy_score(y, y_pred_cv)\n",
    "print(\"Balanced Accuracy (CV):\", round(score_cv, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682031f-ebd0-42f5-8fa4-ab3df06f4798",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo Regresi贸n Log铆stica (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040368c-add0-409c-980f-f38b6e5f162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con validaci贸n cruzada\n",
    "y_proba = cross_val_predict(model, X, y, cv=5, method='predict_proba')\n",
    "y_pred = (y_proba[:, 1] >= 0.5).astype(int)  # convertir probabilidades en clases\n",
    "\n",
    "# M茅tricas\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba[:, 1]), 3))\n",
    "\n",
    "# Matriz de confusi贸n e informe\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee84c1d-5e54-4e6e-b107-05e7a8cb5643",
   "metadata": {},
   "source": [
    "## Random Forest + validaci贸n cruzada (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29fa72-3b3a-42a3-8f53-4321ac51479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "y_proba_rf = cross_val_predict(rf_model, X, y, cv=5, method='predict_proba')\n",
    "y_pred_rf = (y_proba_rf[:, 1] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09394fe6-3647-4f38-adf4-11a641b9d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M茅tricas\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred_rf), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred_rf), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred_rf), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred_rf), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred_rf), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba_rf[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba_rf[:, 1]), 3))\n",
    "\n",
    "# Matriz de confusi贸n e informe\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baee555-0f00-4662-8f3f-4906bf0deb5f",
   "metadata": {},
   "source": [
    "## Modelo Gradient Boosting (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0920d0-8f03-4242-86f5-e1106c1506a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "y_proba_gb = cross_val_predict(gb_model, X, y, cv=5, method='predict_proba')\n",
    "y_pred_gb = (y_proba_gb[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# M茅tricas\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred_gb), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred_gb), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred_gb), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred_gb), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred_gb), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba_gb[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba_gb[:, 1]), 3))\n",
    "\n",
    "# Matriz de confusi贸n e informe\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred_gb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b613c8b-dc2a-4008-bef8-1e0adce84ee9",
   "metadata": {},
   "source": [
    "## Modelo Gradient Boosting balanceado (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0f061-8374-4017-95e8-1f3ea68a59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = HistGradientBoostingClassifier(class_weight='balanced', max_iter=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "y_proba_gb = cross_val_predict(gb_model, X, y, cv=5, method='predict_proba')\n",
    "y_pred_gb = (y_proba_gb[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred_gb), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred_gb), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred_gb), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred_gb), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred_gb), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba_gb[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba_gb[:, 1]), 3))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred_gb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e4a94-5098-48a5-a415-3d87205b25b1",
   "metadata": {},
   "source": [
    "## MLPClassifier (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13725f7-3ac3-4d7a-ad3b-e6ad86827696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo MLP\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # una capa oculta con 100 neuronas\n",
    "    max_iter=300,\n",
    "    alpha=1e-4,\n",
    "    solver='adam',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "y_proba_mlp = cross_val_predict(mlp_model, X, y, cv=5, method='predict_proba')\n",
    "y_pred_mlp = (y_proba_mlp[:, 1] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed3e33a-28aa-4680-ac69-c207ecb15435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M茅tricas\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred_mlp), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred_mlp), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred_mlp), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred_mlp), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred_mlp), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba_mlp[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba_mlp[:, 1]), 3))\n",
    "\n",
    "# Matriz de confusi贸n e informe\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred_mlp))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977f9bc-3146-48d2-aa88-4829e9de815c",
   "metadata": {},
   "source": [
    "## MLPClassifier con SMOTE (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79604e-1429-4304-a1ae-0c35b20a5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Aplicar SMOTE al conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Entrenar MLP sobre datos balanceados\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "mlp_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# 4. Predecir sobre el test original\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "y_proba_mlp = mlp_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# 5. M茅tricas\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_mlp), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y_test, y_pred_mlp), 3))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred_mlp), 3))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred_mlp), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y_test, y_pred_mlp), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y_test, y_proba_mlp[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y_test, y_proba_mlp[:, 1]), 3))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1c1b-a5e9-4cdd-b234-537994457a63",
   "metadata": {},
   "source": [
    "| Modelo                    | Accuracy | Balanced Accuracy | Precision | Recall | F1-Score | AUC-ROC | Log Loss |\n",
    "|--------------------------|----------|--------------------|-----------|--------|----------|---------|----------|\n",
    "| Regresi贸n Log铆stica      | 0.612    | 0.615              | 0.771     | 0.608  | 0.680    | 0.657   | 0.656    |\n",
    "| Random Forest            | 0.673    | 0.548              | 0.701     | 0.901  | 0.789    | 0.646   | 0.606    |\n",
    "| Gradient Boosting        | 0.679    | 0.545              | 0.699     | 0.925  | 0.796    | **0.671** | 0.589 |\n",
    "| Gradient Boosting (bal.) | 0.608    | 0.625              | 0.787 | 0.577  | 0.666    | 0.669   | 0.640    |\n",
    "| MLPClassifier            | 0.679    | 0.555              | 0.704     | 0.906  | 0.793    | **0.666**   | 0.596    |\n",
    "| MLP + SMOTE              | 0.596    | 0.613              | 0.776     | 0.564  | 0.653    | 0.653   | 0.669    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a93479-cde9-41e9-a834-60cb1730aca0",
   "metadata": {},
   "source": [
    "## Mejora de Modelos con mas AUC-ROC : Gradient Bossting y MLPClassifier (GS + M1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096790a-5b82-4fae-b9d2-c67d22828e12",
   "metadata": {},
   "source": [
    "## Modelo Gradient Boosting con Optua (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ded72-1e92-4b76-924d-1dfd1d333735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objetivo de optimizaci贸n\n",
    "def objective(trial):\n",
    "    # Hiperpar谩metros a optimizar\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    # Validaci贸n cruzada\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "        model = GradientBoostingClassifier(\n",
    "            **params,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, sample_weight=weights)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "# Crear y ejecutar estudio\n",
    "study = optuna.create_study(direction='maximize', study_name='GB_AUC_Optimization')\n",
    "study.optimize(objective, n_trials=100, n_jobs=1)  # subir n_trials para mejor resultado\n",
    "\n",
    "# Mostrar mejor resultado\n",
    "print(\" Mejor AUC-ROC:\", round(study.best_value, 4))\n",
    "print(\" Mejores hiperpar谩metros encontrados:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e009e4-323e-46e8-8cb9-177b4ffdbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    " Mejor AUC-ROC: 0.6818\n",
    " Mejores hiperpar谩metros encontrados:\n",
    "{'learning_rate': 0.014538386775171604, 'n_estimators': 475, 'max_depth': 4, 'subsample': 0.5162888716243986}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10bbe2-b993-4ebb-969d-1429618a6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_proba = np.zeros(len(y))\n",
    "y_pred = np.zeros(len(y))\n",
    "\n",
    "# Validaci贸n cruzada manual con los mejores hiperpar谩metros encontrados\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    w = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    model = GradientBoostingClassifier(\n",
    "        learning_rate=0.014538386775171604,\n",
    "        n_estimators=475,\n",
    "        max_depth=4,\n",
    "        subsample=0.5162888716243986,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=w)\n",
    "    y_proba[test_idx] = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred[test_idx] = model.predict(X_test)\n",
    "\n",
    "# Evaluaci贸n\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "print(\"MTRICAS DEL MODELO FINAL (Optuna):\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba), 3))\n",
    "print(\"\\nMatriz de Confusi贸n:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649912c-9a95-4790-b8c8-1f8445c930bf",
   "metadata": {},
   "source": [
    "## MLPClassifier Optua (GS + M1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e70fe6-906f-4099-af25-053f26212b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mostrar progreso en consola\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# Objetivo de optimizaci贸n\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50), (100, 100)]),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1e-2, log=True),\n",
    "        'learning_rate_init': trial.suggest_float('learning_rate_init', 0.0005, 0.1, log=True),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'sgd']),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "    }\n",
    "\n",
    "    aucs = []\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            **params,\n",
    "            max_iter=300,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "# Crear estudio y optimizar\n",
    "study = optuna.create_study(direction='maximize', study_name='MLP_AUC_Optimization')\n",
    "study.optimize(objective, n_trials=150, n_jobs=1)  \n",
    "\n",
    "# Mostrar mejores resultados\n",
    "print(\"Mejor AUC-ROC:\", round(study.best_value, 4))\n",
    "print(\"Mejores hiperpar谩metros encontrados:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bbfb9-812b-4633-97fc-dfe7754fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mejor AUC-ROC: 0.6777\n",
    "Mejores hiperpar谩metros encontrados:\n",
    "{'hidden_layer_sizes': (100, 50), 'alpha': 0.007356732091984054, 'learning_rate_init': 0.003647090832896848, 'solver': 'sgd', 'activation': 'tanh'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a5b17-08b4-41b8-8c5d-297173c7f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modelo con los mejores hiperpar谩metros encontrados por Optuna\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    alpha=0.007356732091984054,\n",
    "    learning_rate_init=0.003647090832896848,\n",
    "    solver='sgd',\n",
    "    activation='tanh',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Validaci贸n cruzada (probabilidades)\n",
    "y_proba = cross_val_predict(best_mlp, X, y, cv=5, method='predict_proba')\n",
    "y_pred = (y_proba[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "# 3. M茅tricas\n",
    "print(\"MTRICAS DEL MLP OPTIMIZADO (Optuna actualizado):\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y, y_pred), 3))\n",
    "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y, y_pred), 3))\n",
    "print(\"Precision:\", round(precision_score(y, y_pred), 3))\n",
    "print(\"Recall:\", round(recall_score(y, y_pred), 3))\n",
    "print(\"F1-Score:\", round(f1_score(y, y_pred), 3))\n",
    "print(\"AUC-ROC:\", round(roc_auc_score(y, y_proba[:, 1]), 3))\n",
    "print(\"Log Loss:\", round(log_loss(y, y_proba[:, 1]), 3))\n",
    "\n",
    "# 4. Matriz de confusi贸n\n",
    "print(\"\\nMatriz de Confusi贸n:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1faec-c706-4b62-a2fe-d3c3442c1d8e",
   "metadata": {},
   "source": [
    "| Modelo                    | Accuracy | Balanced Accuracy | Precision | Recall | F1-Score | AUC-ROC | Log Loss |\n",
    "|--------------------------|----------|--------------------|-----------|--------|----------|---------|----------|\n",
    "| Gradient Boosting (Optuna) | 0.613    | **0.631**          | **0.792** | 0.581  | 0.670    | **0.682** | 0.636    |\n",
    "| MLPClassifier (Optuna)     | **0.682**| 0.545              | 0.698     | **0.934** | **0.799** | 0.672   | **0.588** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b4270-eb3a-4bb7-95b4-a76cc2c89122",
   "metadata": {},
   "source": [
    "### Comparativa de los Mejores Modelos por AUC-ROC\n",
    "\n",
    "| M茅trica               | Grand Slams (GB Optuna) | Masters 1000 (GB Optuna) | GS + M1000 (GB Optuna) | GS + M1000 (MLP Optuna) |\n",
    "|-----------------------|-------------------------|---------------------------|-------------------------|--------------------------|\n",
    "| **Accuracy**          | 0.643                   | 0.594                     | 0.613                   | **0.682**                |\n",
    "| **Balanced Accuracy** | **0.658**               | 0.606                     | **0.631**               | 0.545                    |\n",
    "| **Precision**         | **0.835**               | 0.743                     | **0.792**               | 0.698                    |\n",
    "| **Recall**            | 0.623                   | 0.563                     | 0.581                   | **0.934**                |\n",
    "| **F1-Score**          | 0.714                   | 0.641                     | 0.670                   | **0.799**                |\n",
    "| **AUC-ROC**           | **0.713**               | 0.649                     | **0.682**               | 0.672                    |\n",
    "| **Log Loss**          | 0.613                   | 0.654                     | 0.636                   | **0.588**                |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusi贸n Final\n",
    "\n",
    "- El modelo **Gradient Boosting con Optuna en Grand Slams** sigue siendo el mejor en cuanto a **AUC-ROC (0.713)**, adem谩s de tener el **mejor balance entre precisi贸n y sensibilidad**.\n",
    "- El modelo **combinado (Grand Slams + Masters 1000)** mejora el recall al usar MLP optimizado y alcanza el **mejor F1-Score y Accuracy**, aunque pierde en Balanced Accuracy y AUC.\n",
    "- El conjunto de **Masters 1000** es el m谩s dif铆cil de predecir en t茅rminos de AUC-ROC y precisi贸n general.\n",
    "- Si el objetivo es **m谩xima discriminaci贸n entre clases (AUC-ROC)**, el modelo de Grand Slams con Gradient Boosting es el mejor. Si se prioriza **recall o F1**, el modelo MLP conjunto es m谩s potente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c65aa-758a-47fc-9bc2-f511cbf15c5e",
   "metadata": {},
   "source": [
    "# Comparaci贸n entre modelos entrenados con diferentes datasets\n",
    "# Modelo Conjunto (GS + M1000) o Modelo GrandSlam\n",
    "\n",
    "En este apartado se evaluar谩 si conviene entrenar modelos espec铆ficos por tipo de torneo (como Grand Slams) o si un modelo conjunto entrenado con torneos de tipo **Grand Slam + Masters 1000** puede generalizar mejor a los partidos de alto nivel.\n",
    "\n",
    "####  Objetivo\n",
    "Comparar el rendimiento de dos modelos de **Gradient Boosting (Optuna)** sobre el mismo conjunto de test: **partidos de Grand Slams**.\n",
    "\n",
    "-  **Modelo 1**: Entrenado exclusivamente con datos de torneos **Grand Slam**.\n",
    "-  **Modelo 2**: Entrenado con partidos de **Grand Slam + Masters 1000**.\n",
    "\n",
    "Ambos modelos han sido optimizados con **Optuna** y sus hiperpar谩metros fueron ajustados para maximizar el AUC-ROC.\n",
    "\n",
    "####  Proceso\n",
    "1. Se filtra el dataset para quedarnos 煤nicamente con los partidos de **Grand Slams**.\n",
    "2. Se utilizan ambos modelos ya entrenados para predecir sobre ese conjunto.\n",
    "3. Se comparan las m茅tricas :  \n",
    "   - Accuracy  \n",
    "   - Balanced Accuracy  \n",
    "   - Precision  \n",
    "   - Recall  \n",
    "   - F1-Score  \n",
    "   - AUC-ROC  \n",
    "   - Log Loss  \n",
    "\n",
    "Este an谩lisis permite responder la siguiente pregunta clave del proyecto:\n",
    "\n",
    "> 驴Es preferible entrenar modelos espec铆ficos por tipo de torneo o uno conjunto para todos?\n",
    "\n",
    "Un mejor rendimiento del modelo conjunto sobre los datos de Grand Slams indicar铆a una **mejor generalizaci贸n** al beneficiarse de un mayor volumen y variedad de datos. Por el contrario, si el modelo entrenado solo con datos de Grand Slams ofrece mejores m茅tricas, esto sugiere que la especializaci贸n por tipo de torneo puede ser m谩s eficaz para predecir su resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f580e3-7251-44c8-a8f2-211fbc653e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paso 1: Cargar el dataset ===\n",
    "ruta_base = r\"./Modelo_Completo/columnas_a帽adidas\"\n",
    "nombre_archivo = \"escaladofinal.csv\"\n",
    "ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "\n",
    "df = pd.read_csv(\n",
    "    ruta_completa,\n",
    "    delimiter=\";\",   # separador de columnas\n",
    "    decimal=\",\"      # separador decimal \n",
    ")\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df = df.sort_values(by=\"Date\")\n",
    "\n",
    "# === Corregir comas decimales en las columnas num茅ricas ===\n",
    "features = [\n",
    "    \"Surface_WinRate_Favorite\", \"Surface_WinRate_Not_Favorite\",\n",
    "    \"Surface_Matches_Favorite\", \"Surface_Matches_Not_Favorite\",\n",
    "    \"WinStreak_Favorite\", \"WinStreak_Not_Favorite\", \"Win_Streak_Diff\",\n",
    "    \"Rank_Favorite\", \"Rank_Not_Favorite\", \"Rank_Diff_Signed\", \"Rank_Diff_Abs\",\n",
    "    \"Masters1000_Favorite\", \"Masters1000_Not_Favorite\",\n",
    "    \"GrandSlams_Favorite\", \"GrandSlams_Not_Favorite\"\n",
    "]\n",
    "\n",
    "for col in features:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "\n",
    "# === Separar datos ===\n",
    "df_gs = df[df[\"Series\"] == \"Grand Slam\"].copy()\n",
    "df_comb = df[df[\"Series\"].isin([\"Grand Slam\", \"Masters 1000\"])].copy()\n",
    "\n",
    "X_gs = df_gs[features]\n",
    "y_gs = df_gs[\"Favorite_Wins\"]\n",
    "X_comb = df_comb[features]\n",
    "y_comb = df_comb[\"Favorite_Wins\"]\n",
    "\n",
    "# === Entrenar modelo combinado (fuera del loop para acelerar) ===\n",
    "w_comb = compute_sample_weight(class_weight='balanced', y=y_comb)\n",
    "modelo_combinado = GradientBoostingClassifier(\n",
    "    learning_rate=0.014538386775171604,\n",
    "    n_estimators=475,\n",
    "    max_depth=4,\n",
    "    subsample=0.5162888716243986,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_combinado.fit(X_comb, y_comb, sample_weight=w_comb)\n",
    "\n",
    "# === Validaci贸n cruzada solo en partidos de GS ===\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_gs = np.zeros(len(y_gs))\n",
    "y_proba_gs = np.zeros(len(y_gs))\n",
    "y_pred_comb = np.zeros(len(y_gs))\n",
    "y_proba_comb = np.zeros(len(y_gs))\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_gs, y_gs):\n",
    "    X_train, X_test = X_gs.iloc[train_idx], X_gs.iloc[test_idx]\n",
    "    y_train, y_test = y_gs.iloc[train_idx], y_gs.iloc[test_idx]\n",
    "    w = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    modelo_gs = GradientBoostingClassifier(\n",
    "        learning_rate=0.0222992728201512,\n",
    "        n_estimators=484,\n",
    "        max_depth=3,\n",
    "        subsample=0.6374765489547842,\n",
    "        random_state=42\n",
    "    )\n",
    "    modelo_gs.fit(X_train, y_train, sample_weight=w)\n",
    "\n",
    "    y_pred_gs[test_idx] = modelo_gs.predict(X_test)\n",
    "    y_proba_gs[test_idx] = modelo_gs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    y_pred_comb[test_idx] = modelo_combinado.predict(X_test)\n",
    "    y_proba_comb[test_idx] = modelo_combinado.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# === Funci贸n de evaluaci贸n ===\n",
    "def evaluar(nombre, y_true, y_pred, y_proba):\n",
    "    print(f\"\\n--- {nombre} ---\")\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 3))\n",
    "    print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y_true, y_pred), 3))\n",
    "    print(\"Precision:\", round(precision_score(y_true, y_pred), 3))\n",
    "    print(\"Recall:\", round(recall_score(y_true, y_pred), 3))\n",
    "    print(\"F1 Score:\", round(f1_score(y_true, y_pred), 3))\n",
    "    print(\"AUC-ROC:\", round(roc_auc_score(y_true, y_proba), 3))\n",
    "    print(\"Log Loss:\", round(log_loss(y_true, y_proba), 3))\n",
    "    print(\"Matriz de Confusi贸n:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# === Resultados ===\n",
    "y_true = y_gs.to_numpy()\n",
    "evaluar(\"Modelo SOLO Grand Slams\", y_true, y_pred_gs.astype(int), y_proba_gs)\n",
    "evaluar(\"Modelo COMBINADO (entrenado en GS + M1000)\", y_true, y_pred_comb.astype(int), y_proba_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2841a7-70e5-4a56-8594-6912c5dfc39a",
   "metadata": {},
   "source": [
    "###  Comparativa de Modelos: Evaluaci贸n sobre Partidos de Grand Slams\n",
    "\n",
    "| M茅trica               | GB (Solo GS) | GB (GS + M1000) |\n",
    "|-----------------------|--------------|------------------|\n",
    "| **Accuracy**          | 0.641        | **0.669**        |\n",
    "| **Balanced Accuracy** | 0.656        | **0.685**        |\n",
    "| **Precision**         | 0.834        | **0.853**        |\n",
    "| **Recall**            | 0.620        | **0.648**        |\n",
    "| **F1-Score**          | 0.711        | **0.737**        |\n",
    "| **AUC-ROC**           | 0.713        | **0.752**        |\n",
    "| **Log Loss**          | 0.612        | **0.585**        |\n",
    "\n",
    "---\n",
    "\n",
    "###  Evaluaci贸n del modelo combinado sobre todos los torneos (GS + M1000)\n",
    "\n",
    "| M茅trica               | Valor         |\n",
    "|-----------------------|---------------|\n",
    "| **Accuracy**          | 0.613         |\n",
    "| **Balanced Accuracy** | 0.631         |\n",
    "| **Precision**         | 0.792         |\n",
    "| **Recall**            | 0.581         |\n",
    "| **F1-Score**          | 0.670         |\n",
    "| **AUC-ROC**           | 0.682         |\n",
    "| **Log Loss**          | 0.636         |\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusiones sobre Grand Slams\n",
    "\n",
    "- El modelo **combinado (entrenado con Grand Slams + Masters 1000)** mejora claramente en todos los aspectos cuando se eval煤a exclusivamente en partidos de Grand Slam:\n",
    "  - **Mejor discriminaci贸n (AUC-ROC: 0.752)**\n",
    "  - **Mayor precisi贸n y recall**\n",
    "  - **Menor log loss**\n",
    "\n",
    "- Esto indica que los datos de Masters 1000 **aportan conocimiento 煤til que generaliza bien hacia los partidos de Grand Slam**, posiblemente porque:\n",
    "  - Ambos tipos de torneos son de alto nivel competitivo.\n",
    "  - Jugadores y condiciones similares permiten al modelo extraer patrones adicionales que no estaban presentes solo en los Grand Slams.\n",
    "\n",
    "---\n",
    "\n",
    "### 驴Por qu茅 el modelo combinado rinde peor cuando se le eval煤a sobre *todos los torneos*?\n",
    "\n",
    "- Cuando el modelo se eval煤a sobre **el conjunto completo de partidos (GS + M1000)**, su rendimiento baja notablemente:\n",
    "  - **Accuracy pasa de 0.669 (en GS) a 0.613 (en total)**\n",
    "  - **AUC-ROC cae de 0.752 a 0.682**\n",
    "\n",
    "Esto puede deberse a:\n",
    "\n",
    "1. **Mayor variabilidad en los partidos de Masters 1000:**\n",
    "   - Estos torneos pueden incluir m谩s sorpresas, rotaciones, lesiones, o jugadores menos constantes, lo que introduce m谩s *ruido* en los datos.\n",
    "\n",
    "2. **Desbalance estructural m谩s complejo:**\n",
    "   - El conjunto combinado tiene a煤n m谩s partidos con el favorito ganando, lo que puede desestabilizar el equilibrio del modelo.\n",
    "\n",
    "3. **Contexto competitivo distinto:**\n",
    "   - Aunque ambos torneos son de nivel alto, **la motivaci贸n, duraci贸n, y preparaci贸n** de los jugadores puede variar. En Grand Slams hay m谩s al mejor de 5 sets, lo que tiende a beneficiar al favorito.\n",
    "\n",
    "4. **Dificultad del problema:**\n",
    "   - Predecir correctamente todos los torneos a la vez implica aprender a manejar **m谩s heterogeneidad** (distintas superficies, niveles de presi贸n, jugadores en forma o en baja), lo cual es m谩s dif铆cil.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusi贸n Final\n",
    "\n",
    "> **Entrenar con datos de Masters 1000 ayuda al modelo a predecir mejor los Grand Slams**, pero esa ganancia **no se transfiere al predecir ambos tipos de torneo simult谩neamente**, donde el modelo enfrenta mayor complejidad y menor consistencia en los patrones.\n",
    "\n",
    "Esto resalta la importancia de:\n",
    "- Evaluar los modelos seg煤n el objetivo espec铆fico.\n",
    "- No asumir que m谩s datos siempre implican mejor rendimiento en todos los escenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc807239-9b56-4224-9243-e56dcc559756",
   "metadata": {},
   "source": [
    "# Comparaci贸n entre modelos entrenados con diferentes datasets  \n",
    "## Modelo Conjunto (GS + M1000) vs. Modelo Masters 1000\n",
    "\n",
    "En este apartado se evaluar谩 si conviene entrenar modelos espec铆ficos por tipo de torneo (como los **Masters 1000**) o si un modelo conjunto entrenado con torneos de tipo **Grand Slam + Masters 1000** puede generalizar mejor a los partidos de alto nivel.\n",
    "\n",
    "---\n",
    "\n",
    "### Objetivo\n",
    "Comparar el rendimiento de dos modelos de **Gradient Boosting (Optuna)** sobre el mismo conjunto de test: **partidos de Masters 1000**.\n",
    "\n",
    "-  **Modelo 1**: Entrenado exclusivamente con datos de torneos **Masters 1000**.  \n",
    "-  **Modelo 2**: Entrenado con partidos de **Masters 1000 + Grand Slam**.\n",
    "\n",
    "Ambos modelos han sido optimizados con **Optuna** y sus hiperpar谩metros fueron ajustados espec铆ficamente para maximizar el rendimiento en sus datasets respectivos.\n",
    "\n",
    "---\n",
    "\n",
    "### Proceso\n",
    "1. Se filtra el dataset para quedarnos 煤nicamente con los partidos de **Masters 1000**.\n",
    "2. Se realiza validaci贸n cruzada estratificada para evaluar ambos modelos exclusivamente sobre estos partidos.\n",
    "3. Se comparan las siguientes m茅tricas:\n",
    "   - Accuracy  \n",
    "   - Balanced Accuracy  \n",
    "   - Precision  \n",
    "   - Recall  \n",
    "   - F1-Score  \n",
    "   - AUC-ROC  \n",
    "   - Log Loss  \n",
    "\n",
    "Este an谩lisis permite responder la siguiente pregunta clave del proyecto:\n",
    "\n",
    "> 驴Es preferible entrenar modelos espec铆ficos para torneos Masters 1000, o un modelo conjunto con m谩s variedad de datos mejora la predicci贸n?\n",
    "\n",
    "Un mejor rendimiento del modelo conjunto sobre los datos de Masters 1000 indicar铆a una **mejor capacidad de generalizaci贸n**, posiblemente debido al uso de una mayor diversidad de ejemplos competitivos. Por el contrario, si el modelo entrenado exclusivamente con datos de Masters 1000 ofrece mejores resultados, esto sugiere que la especializaci贸n por tipo de torneo puede ser m谩s eficaz para capturar patrones propios de estos eventos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fb1d1-ef45-4776-9032-7aa3718bb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separar datasets \n",
    "df_m1000 = df[df[\"Series\"] == \"Masters 1000\"].copy()\n",
    "df_combined = df[df[\"Series\"].isin([\"Grand Slam\", \"Masters 1000\"])].copy()\n",
    "\n",
    "X_m1000 = df_m1000[features]\n",
    "y_m1000 = df_m1000[\"Favorite_Wins\"]\n",
    "X_comb = df_combined[features]\n",
    "y_comb = df_combined[\"Favorite_Wins\"]\n",
    "\n",
    "# === Modelo combinado (entrenado una vez) ===\n",
    "w_comb = compute_sample_weight(class_weight='balanced', y=y_comb)\n",
    "modelo_combinado = GradientBoostingClassifier(\n",
    "    learning_rate=0.014538386775171604,\n",
    "    n_estimators=475,\n",
    "    max_depth=4,\n",
    "    subsample=0.5162888716243986,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_combinado.fit(X_comb, y_comb, sample_weight=w_comb)\n",
    "\n",
    "#  Validaci贸n cruzada para evaluaci贸n en M1000 \n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_m1000 = np.zeros(len(y_m1000))\n",
    "y_proba_m1000 = np.zeros(len(y_m1000))\n",
    "y_pred_comb = np.zeros(len(y_m1000))\n",
    "y_proba_comb = np.zeros(len(y_m1000))\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_m1000, y_m1000):\n",
    "    X_train, X_test = X_m1000.iloc[train_idx], X_m1000.iloc[test_idx]\n",
    "    y_train, y_test = y_m1000.iloc[train_idx], y_m1000.iloc[test_idx]\n",
    "    w_m1000 = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    modelo_m1000 = GradientBoostingClassifier(\n",
    "        learning_rate=0.011215234584834815,\n",
    "        n_estimators=392,\n",
    "        max_depth=4,\n",
    "        subsample=0.7922129095414916,\n",
    "        random_state=42\n",
    "    )\n",
    "    modelo_m1000.fit(X_train, y_train, sample_weight=w_m1000)\n",
    "\n",
    "    y_pred_m1000[test_idx] = modelo_m1000.predict(X_test)\n",
    "    y_proba_m1000[test_idx] = modelo_m1000.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    y_pred_comb[test_idx] = modelo_combinado.predict(X_test)\n",
    "    y_proba_comb[test_idx] = modelo_combinado.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluaci贸n final\n",
    "def evaluar_modelo(nombre, y_true, y_pred, y_proba):\n",
    "    print(f\"\\n--- MTRICAS: {nombre} ---\")\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 3))\n",
    "    print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y_true, y_pred), 3))\n",
    "    print(\"Precision:\", round(precision_score(y_true, y_pred), 3))\n",
    "    print(\"Recall:\", round(recall_score(y_true, y_pred), 3))\n",
    "    print(\"F1-Score:\", round(f1_score(y_true, y_pred), 3))\n",
    "    print(\"AUC-ROC:\", round(roc_auc_score(y_true, y_proba), 3))\n",
    "    print(\"Log Loss:\", round(log_loss(y_true, y_proba), 3))\n",
    "    print(\"Matriz de Confusi贸n:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# === Resultados ===\n",
    "evaluar_modelo(\"Modelo SOLO Masters 1000\", y_m1000, y_pred_m1000.astype(int), y_proba_m1000)\n",
    "evaluar_modelo(\"Modelo COMBINADO (entrenado en GS + M1000)\", y_m1000, y_pred_comb.astype(int), y_proba_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ac8c7-2405-4325-a211-31b3668f3bc2",
   "metadata": {},
   "source": [
    "###  Comparativa de Modelos: Evaluaci贸n sobre Partidos de Masters 1000\n",
    "\n",
    "| M茅trica               | GB (Solo M1000) | GB (GS + M1000) |\n",
    "|-----------------------|------------------|------------------|\n",
    "| **Accuracy**          | 0.598            | **0.605**        |\n",
    "| **Balanced Accuracy** | 0.612            | **0.634**        |\n",
    "| **Precision**         | 0.756            | **0.789**        |\n",
    "| **Recall**            | **0.568**        | 0.540            |\n",
    "| **F1-Score**          | **0.649**        | 0.641            |\n",
    "| **AUC-ROC**           | 0.650            | **0.694**        |\n",
    "| **Log Loss**          | 0.652            | **0.639**        |\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusiones sobre Masters 1000\n",
    "\n",
    "- El modelo **combinado (entrenado con Grand Slams + Masters 1000)** mejora en:\n",
    "  - **Precision (0.789 vs 0.756)**\n",
    "  - **Balanced Accuracy (0.634 vs 0.612)**\n",
    "  - **AUC-ROC (0.694 vs 0.650)**\n",
    "  - **Log Loss (0.639 vs 0.652)**\n",
    "\n",
    "  Lo cual sugiere una **mejor discriminaci贸n entre clases** y mayor robustez general en sus predicciones.\n",
    "\n",
    "- Por otro lado, el modelo **entrenado exclusivamente en Masters 1000** presenta:\n",
    "  - **Mejor recall (0.568 vs 0.540)**\n",
    "  - **Mejor F1-Score (0.649 vs 0.641)**\n",
    "\n",
    "  Esto indica que tiene **mejor capacidad para detectar victorias reales del favorito**, sacrificando algo de precisi贸n.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusi贸n Final\n",
    "\n",
    "> Aunque el modelo especializado en Masters 1000 obtiene mejor **recall y F1**, el modelo conjunto ofrece **mejor discriminaci贸n general y precisi贸n**.\n",
    "\n",
    "Esto sugiere que:\n",
    "- El modelo combinado es 煤til cuando se busca **consistencia general**.\n",
    "- El modelo espec铆fico de Masters 1000 puede ser preferido si se prioriza **capturar m谩s victorias reales del favorito**, aunque eso implique m谩s falsos positivos.\n",
    "\n",
    "Ambos enfoques tienen valor, y la elecci贸n entre ellos depender谩 del **objetivo final del sistema de predicci贸n**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
