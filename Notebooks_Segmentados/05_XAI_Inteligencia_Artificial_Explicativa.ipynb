{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14b0fcf-fcdd-41a4-ba55-626a9f76cc94",
   "metadata": {},
   "source": [
    "#  XAI – Inteligencia Artificial Explicable\n",
    "\n",
    "En esta sección se aplican técnicas de **Inteligencia Artificial Explicable (XAI)** con el objetivo de entender mejor cómo y por qué los modelos realizan sus predicciones. Esto resulta especialmente útil para validar la coherencia del modelo y detectar posibles sesgos o patrones inesperados.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "El propósito es analizar las decisiones del modelo entrenado (Gradient Boosting optimizado con Optuna de GS + M1000) utilizando dos herramientas complementarias:\n",
    "\n",
    "- **LIME (Local Interpretable Model-Agnostic Explanations):**  \n",
    "  Explica la predicción de un partido individual mostrando cómo cada variable influyó en la decisión.\n",
    "\n",
    "- **SHAP (SHapley Additive exPlanations):**  \n",
    "  Proporciona interpretaciones tanto locales (una predicción concreta) como globales (importancia de variables a nivel general).\n",
    "\n",
    "---\n",
    "\n",
    "## Herramientas y técnicas\n",
    "\n",
    "| Técnica | Tipo de explicación | Aplicación en el proyecto              |\n",
    "|---------|---------------------|-----------------------------------------|\n",
    "| **LIME** | Local               | Explicación detallada de un partido específico: ¿por qué el modelo predijo que ganaba el favorito? |\n",
    "| **SHAP** | Local & Global      | - Análisis de un partido concreto.<br>- Análisis general de las variables más importantes en todas las predicciones. |\n",
    "\n",
    "---\n",
    "\n",
    "## Procedimiento\n",
    "\n",
    "1. **Seleccionar un partido de ejemplo** del dataset de Grand Slams + Masters 1000 para explicar la predicción.\n",
    "2. **Aplicar LIME**:\n",
    "   - Generar una explicación que indique qué características empujaron la predicción hacia “ganar” o “no ganar”.\n",
    "3. **Aplicar SHAP**:\n",
    "   - Explicar cómo cada variable influyó en la predicción de un partido específico.\n",
    "   - Visualizar la importancia global de las variables en el comportamiento general del modelo.\n",
    "4. **Extraer conclusiones** sobre la coherencia del modelo y la relevancia de las variables.\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados esperados\n",
    "\n",
    "- Gráficas de LIME mostrando la contribución de cada variable en un partido concreto.\n",
    "- Gráficas de SHAP para:\n",
    "  - Explicación local (partido individual).\n",
    "  - Explicación global (importancia de variables en el dataset completo).\n",
    "\n",
    "---\n",
    "\n",
    "## Justificación\n",
    "\n",
    "Aplicar estas técnicas permitirá responder preguntas como:\n",
    "- ¿El modelo toma decisiones razonables y basadas en datos relevantes?\n",
    "- ¿Existen variables con demasiada influencia que puedan generar sesgos?\n",
    "- ¿Es consistente la importancia de las variables entre los partidos y en el conjunto global?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d731875-aa69-4852-97dc-064a4e97231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos \n",
    "ruta_base = r\"./Modelo_Completo/columnas_añadidas\"\n",
    "nombre_archivo = \"escaladofinal.csv\"\n",
    "ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "\n",
    "df = pd.read_csv(ruta_completa, delimiter=\";\", decimal=\",\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df = df.sort_values(by=\"Date\")\n",
    "\n",
    "# Selección de características y target\n",
    "features = [\n",
    "    \"Surface_WinRate_Favorite\", \"Surface_WinRate_Not_Favorite\",\n",
    "    \"Surface_Matches_Favorite\", \"Surface_Matches_Not_Favorite\",\n",
    "    \"WinStreak_Favorite\", \"WinStreak_Not_Favorite\", \"Win_Streak_Diff\",\n",
    "    \"Rank_Favorite\", \"Rank_Not_Favorite\", \"Rank_Diff_Signed\", \"Rank_Diff_Abs\",\n",
    "    \"Masters1000_Favorite\", \"Masters1000_Not_Favorite\",\n",
    "    \"GrandSlams_Favorite\", \"GrandSlams_Not_Favorite\"\n",
    "]\n",
    "target = \"Favorite_Wins\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651fb95-26f4-4ba9-b434-8ee49a018d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Modelo (Optuna) ---\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.014538386775171604,\n",
    "    n_estimators=475,\n",
    "    max_depth=4,\n",
    "    subsample=0.5162888716243986,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Seleccionar 2 partidos extremos:\n",
    "#   - HIGH: P(Gana favorito) >= 0.70\n",
    "#   - LOW : P(Gana favorito) <= 0.30\n",
    "\n",
    "\n",
    "# Probabilidades por clase según el modelo\n",
    "probs = model.predict_proba(X)  # shape (n_samples, n_clases)\n",
    "\n",
    "# IDENTIFICAR el índice de la clase \"Gana favorito\".\n",
    "classes = model.classes_\n",
    "name_map = {0: \"No gana favorito\", 1: \"Gana favorito\"}\n",
    "# Fallback por si las clases no son 0/1:\n",
    "class_names_by_model = [name_map.get(c, str(c)) for c in classes]\n",
    "\n",
    "# Índice de la clase \"Gana favorito\" (si no existe 1, toma la de mayor etiqueta como positivo)\n",
    "if 1 in classes:\n",
    "    pos_idx = int(np.where(classes == 1)[0][0])\n",
    "else:\n",
    "    pos_idx = int(np.argmax(classes))  #la clase \"mayor\" como positiva\n",
    "\n",
    "p_fav = probs[:, pos_idx]  # P(Gana favorito)\n",
    "\n",
    "# Índices que cumplen los umbrales\n",
    "high_candidates = np.where(p_fav >= 0.70)[0]\n",
    "low_candidates  = np.where(p_fav <= 0.30)[0]\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def pick_fallback(candidates, target_prob, pick_low=True):\n",
    "    \"\"\"Si no hay candidatos, elige el más cercano al target_prob.\"\"\"\n",
    "    if len(candidates) > 0:\n",
    "        return int(rng.choice(candidates))\n",
    "    # Fallback: índice cuya probabilidad esté más cerca de target_prob\n",
    "    return int(np.argmin(np.abs(p_fav - target_prob)))\n",
    "\n",
    "idx_high = pick_fallback(high_candidates, 0.85, pick_low=False)\n",
    "idx_low  = pick_fallback(low_candidates, 0.15, pick_low=True)\n",
    "\n",
    "print(f\"Partido HIGH (fav >= 0.70) -> idx {idx_high}, P_fav={p_fav[idx_high]:.3f}\")\n",
    "print(f\"Partido LOW  (fav <= 0.30) -> idx {idx_low},  P_fav={p_fav[idx_low]:.3f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# LIME: configuramos el explicador\n",
    "# -------------------------------\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X),\n",
    "    feature_names=list(X.columns) if 'features' not in globals() else features,\n",
    "    class_names=class_names_by_model,   # importante: MISMO ORDEN que model.predict_proba\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=True,        \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Generar explicaciones para ambos casos\n",
    "num_features = 10  # top-10 variables\n",
    "\n",
    "# Caso HIGH (favorito muy probable)\n",
    "exp_high = explainer.explain_instance(\n",
    "    data_row=X.iloc[idx_high].values,\n",
    "    predict_fn=model.predict_proba,\n",
    "    num_features=num_features\n",
    ")\n",
    "exp_high.show_in_notebook(show_table=True, show_all=False)\n",
    "exp_high.save_to_file('lime_explanation_high_70.html')\n",
    "print(\"Explicación HIGH guardada en lime_explanation_high_70.html\")\n",
    "\n",
    "# Caso LOW (favorito poco probable)\n",
    "exp_low = explainer.explain_instance(\n",
    "    data_row=X.iloc[idx_low].values,\n",
    "    predict_fn=model.predict_proba,\n",
    "    num_features=num_features\n",
    ")\n",
    "exp_low.show_in_notebook(show_table=True, show_all=False)\n",
    "exp_low.save_to_file('lime_explanation_low_30.html')\n",
    "print(\"Explicación LOW guardada en lime_explanation_low_30.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf73e3e-c476-46a5-99e6-531419ddb5fc",
   "metadata": {},
   "source": [
    "> Importante: En las gráficas de LIME los bloques azules y naranjas **no representan probabilidades absolutas** que se puedan sumar (por ejemplo, no se espera que los azules sumen exactamente 0.25).  \n",
    "> Lo que muestran son **contribuciones locales**:  \n",
    "> - **Naranja** → variables que empujan la predicción hacia *“Gana favorito”*.  \n",
    "> - **Azul** → variables que empujan la predicción hacia *“No gana favorito”*.  \n",
    "> - **La longitud del bloque** refleja la **fuerza relativa** de esa variable en este partido.  \n",
    "> El balance global de todas las contribuciones aproxima la probabilidad final (ej. 75% favorito – 25% no favorito), pero no es una suma exacta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064292c6-8767-4d5d-88d2-5f2655f3ca54",
   "metadata": {},
   "source": [
    "### Caso 1 – Favorito (75% probabilidad de ganar)\n",
    "\n",
    "- El modelo predice que el **favorito ganará con un 75% de probabilidad**.  \n",
    "- Factores que favorecen al favorito:  \n",
    "  - **Mal rendimiento del no favorito en esta superficie** (`Surface_WinRate_Not_Favorite = 0.70`).  \n",
    "  - **Mejor racha de victorias del favorito** (`Win_Streak_Diff = 0.30`).  \n",
    "- Factores que van en contra del favorito:  \n",
    "  - **Pocos partidos del favorito en esta superficie** (`Surface_Matches_Favorite = -0.59`).  \n",
    "  - **Cierta experiencia del no favorito en Masters1000** (`Masters1000_Not_Favorite = -0.14`).  \n",
    "\n",
    "Aunque existen debilidades (poca experiencia del favorito en la superficie), el mal rendimiento histórico del no favorito pesa más, lo que inclina la predicción hacia el favorito.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b96b2c-2087-4b6f-b027-85aa74784587",
   "metadata": {},
   "source": [
    "### Caso 2 – No favorito (72% probabilidad de ganar)\n",
    "\n",
    "El modelo predice que el **no favorito ganará con un 72% de probabilidad**, frente a un 28% del favorito.\n",
    "\n",
    "**Factores que favorecen al no favorito:**\n",
    "- Buen rendimiento en la superficie (`Surface_WinRate_Not_Favorite = 1.12`).\n",
    "- Mayor número de partidos jugados en la superficie (`Surface_Matches_Not_Favorite = 1.01`).\n",
    "- Diferencia de ranking a su favor (`Rank_Diff_Signed = 0.36`).\n",
    "\n",
    "**Factores que van en contra del no favorito (a favor del favorito):**\n",
    "- Buen winrate del favorito en la superficie (`Surface_WinRate_Favorite = -2.67`).\n",
    "- Experiencia del favorito en esta superficie (`Surface_Matches_Favorite = -0.74`).\n",
    "- Experiencia del no favorito en torneos Masters1000 (`Masters1000_Not_Favorite = -0.14`).\n",
    "\n",
    "Aunque el favorito tiene un buen historial en la superficie y experiencia en torneos importantes, el modelo considera más relevantes el **rendimiento reciente y la experiencia acumulada del no favorito en la superficie**, lo que inclina la predicción a su favor con un 72% de probabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be27739-dda3-40ab-bb91-98b7accff4f7",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "Tras aplicar LIME para entender casos individuales, utilizamos **SHAP** como técnica complementaria de Inteligencia Artificial Explicable.  \n",
    "SHAP se basa en los valores de *Shapley* de la teoría de juegos y permite descomponer la predicción de un modelo en **contribuciones de cada variable**.\n",
    "\n",
    "- **Explicación local:** muestra cómo cada característica concreta ha influido en la predicción de un partido específico.  \n",
    "- **Explicación global:** permite identificar qué variables son más relevantes en el comportamiento general del modelo y cómo afectan sus valores (altos o bajos) a la probabilidad de victoria.\n",
    "\n",
    "De esta forma, SHAP nos ayuda a validar si el modelo toma decisiones coherentes y a detectar posibles sesgos en el conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5ebad-eb6d-42fc-9cfd-de3f7bad40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir y entrenar modelo\n",
    "\n",
    "# Modelo final optimizado con Optuna\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.014538386775171604,\n",
    "    n_estimators=475,\n",
    "    max_depth=4,\n",
    "    subsample=0.5162888716243986,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar con todo el dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# SHAP: explicaciones\n",
    "\n",
    "shap.initjs()  # habilita visualizaciones interactivas en notebook\n",
    "\n",
    "# Crear explicador basado en árboles\n",
    "explainer = shap.TreeExplainer(model)\n",
    "raw_shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Índice de la clase \"Gana favorito\"\n",
    "classes = getattr(model, \"classes_\", np.array([0, 1]))\n",
    "pos_idx = int(np.where(classes == 1)[0][0]) if 1 in classes else int(np.argmax(classes))\n",
    "\n",
    "# Normalizar salida para binario/multiclase\n",
    "if isinstance(raw_shap_values, list):\n",
    "    sv = raw_shap_values[pos_idx]\n",
    "    expected = explainer.expected_value[pos_idx]\n",
    "else:\n",
    "    sv = raw_shap_values\n",
    "    expected = explainer.expected_value\n",
    "\n",
    "\n",
    "# Explicación global\n",
    "\n",
    "# importancia de variables (ranking)\n",
    "plt.figure()\n",
    "shap.summary_plot(sv, X, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_global_importance_bar.png\", dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# b) Dispersión (beeswarm): muestra cómo afectan valores altos/bajos\n",
    "plt.figure()\n",
    "shap.summary_plot(sv, X, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_global_beeswarm.png\", dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Guardadas: shap_global_importance_bar.png, shap_global_beeswarm.png\")\n",
    "\n",
    "\n",
    "# Explicaciones locales\n",
    "\n",
    "# Elegimos partidos extremos como en LIME\n",
    "probs = model.predict_proba(X)[:, pos_idx]\n",
    "high_candidates = np.where(probs >= 0.70)[0]\n",
    "low_candidates  = np.where(probs <= 0.30)[0]\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "def pick(cands, target):\n",
    "    return int(rng.choice(cands)) if len(cands) else int(np.argmin(np.abs(probs - target)))\n",
    "\n",
    "idx_high = pick(high_candidates, 0.85)\n",
    "idx_low  = pick(low_candidates, 0.15)\n",
    "\n",
    "print(f\"Partido HIGH (favorito fuerte): idx={idx_high}, P_fav={probs[idx_high]:.2f}\")\n",
    "print(f\"Partido LOW  (no favorito fuerte): idx={idx_low}, P_fav={probs[idx_low]:.2f}\")\n",
    "\n",
    "# a) Force plot (HIGH)\n",
    "fig = shap.force_plot(expected, sv[idx_high, :], X.iloc[idx_high, :], matplotlib=True, show=False)\n",
    "plt.title(f\"SHAP force plot – Favorito ≈ {probs[idx_high]:.2f}\")\n",
    "plt.savefig(\"shap_local_force_high.png\", dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# b) Force plot (LOW)\n",
    "fig = shap.force_plot(expected, sv[idx_low, :], X.iloc[idx_low, :], matplotlib=True, show=False)\n",
    "plt.title(f\"SHAP force plot – Favorito ≈ {probs[idx_low]:.2f}\")\n",
    "plt.savefig(\"shap_local_force_low.png\", dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Guardadas: shap_local_force_high.png, shap_local_force_low.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fff690-1678-421f-80cb-c7d888f36f48",
   "metadata": {},
   "source": [
    "### Explicaciones con SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) permite descomponer las predicciones del modelo en **contribuciones de cada variable**.  \n",
    "Los valores SHAP se interpretan así:  \n",
    "- **Positivos (rojo)** → aumentan la probabilidad de que gane el favorito.  \n",
    "- **Negativos (azul)** → reducen la probabilidad de que gane el favorito.  \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Importancia global (bar plot)\n",
    "\n",
    "El gráfico de barras muestra la **importancia media absoluta** de cada variable en todas las predicciones.  \n",
    "Las más influyentes en el modelo son:\n",
    "\n",
    "- **Surface_WinRate_Favorite**  \n",
    "- **Rank_Favorite**  \n",
    "- **Surface_WinRate_Not_Favorite**  \n",
    "- **Rank_Diff_Signed** y **Rank_Diff_Abs**\n",
    "\n",
    "Esto confirma que el modelo se apoya sobre todo en **rendimiento en superficie** y **ranking de los jugadores** para tomar decisiones.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Comportamiento global (beeswarm)\n",
    "\n",
    "El gráfico de dispersión (beeswarm) muestra, además de la importancia, **cómo influyen los valores altos o bajos** de cada variable:\n",
    "\n",
    "- **Surface_WinRate_Favorite** alto (rojo) → aumenta la probabilidad de victoria del favorito.  \n",
    "- **Surface_WinRate_Not_Favorite** alto (rojo) → reduce la probabilidad de victoria del favorito.  \n",
    "- **Rank_Favorite** bajo (mejor ranking) → favorece al favorito; alto (peor ranking) → lo perjudica.\n",
    "\n",
    "Esto refleja patrones consistentes y lógicos: el modelo confía en la calidad del favorito y en el mal desempeño del no favorito en la superficie.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Explicación local – Caso LOW (P_fav ≈ 0.28)\n",
    "\n",
    "El modelo predice que el favorito tiene solo un **28% de probabilidad de ganar**.  \n",
    "\n",
    "Principales factores en contra del favorito:\n",
    "- **Surface_WinRate_Favorite** (−0.51) → el favorito tiene mal rendimiento en esa superficie.  \n",
    "- **Surface_WinRate_Not_Favorite** (−0.39) → el no favorito tiene buen winrate en la superficie.  \n",
    "- **Rank_Diff_Abs** (−0.23) y **Rank_Diff_Signed** (−0.22) → la diferencia de ranking no favorece al favorito.  \n",
    "- **Surface_Matches_Not_Favorite** (−0.16) → el no favorito ha jugado más en la superficie.  \n",
    "\n",
    "El no favorito aparece mejor posicionado por experiencia en la superficie y ranking, lo que lleva al modelo a asignarle ventaja.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Explicación local – Caso HIGH (P_fav ≈ 0.75)\n",
    "\n",
    "En este partido, el favorito tiene un **75% de probabilidad de ganar**.  \n",
    "\n",
    "Principales factores a favor del favorito:\n",
    "- **Surface_Matches_Not_Favorite** (+0.15) → poca experiencia del no favorito en la superficie.  \n",
    "- **Rank_Diff_Abs** (+0.14) y **Rank_Diff_Signed** (+0.13) → la diferencia de ranking favorece al favorito.  \n",
    "- Aportes menores: **Surface_WinRate_Favorite** (+0.04), **Rank_Not_Favorite** (+0.04), **Win_Streak_Diff** (+0.03).  \n",
    "\n",
    "Factores en contra:\n",
    "- **Surface_WinRate_Not_Favorite** (−0.14).  \n",
    "- **Rank_Favorite** (−0.09).  \n",
    "- **Masters1000_Favorite** (−0.04).  \n",
    "\n",
    " Aunque existen variables que restan (por ejemplo, cierto rendimiento del no favorito), la ventaja en **ranking** y la **poca experiencia del no favorito en la superficie** hacen que el modelo apueste claramente por el favorito.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones generales\n",
    "\n",
    "- **SHAP global** confirma que el modelo se basa principalmente en **win rates por superficie** y **ranking**.  \n",
    "- **SHAP local** permite entender por qué en partidos concretos el modelo favorece o no al favorito.  \n",
    "- En el caso **LOW**, el no favorito domina por rendimiento en superficie y ranking.  \n",
    "- En el caso **HIGH**, el favorito domina gracias a la diferencia de ranking y la falta de experiencia del rival en la superficie.  \n",
    "\n",
    "Esto demuestra que el modelo toma decisiones coherentes y basadas en información relevante.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
